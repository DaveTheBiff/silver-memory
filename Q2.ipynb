{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05980e3e",
   "metadata": {},
   "source": [
    "# Question 2 - Case Study II: High-Performance Data Processing (Week 2) @ SISNET:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474a31a0",
   "metadata": {},
   "source": [
    "Scenario: Your team is processing a 10GB transaction log file daily. The current Python script uses a standard for loop to iterate through rows, apply a currency conversion, and filter out failed transactions. This process currently takes 6 hours to complete, delaying downstream reporting.\n",
    "\n",
    "Q2.1 (Performance Diagnosis): Analyse why native Python loops are computationally expensive for large datasets compared to NumPy/Pandas operations. In your explanation, reference concepts such as Type Checking, Interpreter Overhead, and SIMD/C-Level Execution.\n",
    "\n",
    "Q2.2 (Refactoring Plan): Provide a conceptual refactoring plan (pseudocode or Python snippet) using Pandas Vectorisation. Estimate the theoretical performance gain and explain the trade-offs (e.g. Memory Usage).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43be71",
   "metadata": {},
   "source": [
    "Q2.1:\n",
    "Native Python loops are significantly slower than NumPy or Pandas because Python is designed for flexibility and not speed. When you run a standard \"for\" loop, the Python Interpreter must perform Type Checking at every single step. As Python is dynamic, it does not know if a variable is an integer, a string, or a list until it actually reads it during its runtime. This creates a lot of Interpreter Overhead and time lag as the computer spends more time figuring out what data types it is handling than actually performing the math.\n",
    "\n",
    "In contrast, NumPy and Pandas uses C-Level Execution, where data types are fixed and known in advance. This allows for SIMD (Single Instruction, Multiple Data) processing. SIMD allows the CPU to perform the same operation on a whole block of data at once, rather than one part at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bdab52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop Method: 0.2419 seconds\n",
      "Vectorized Method: 0.0018 seconds\n",
      "Speedup Factor: 136.68x\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Docstring for Q2.2:\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "# 1. Create a sample dataset with 1000000 rows\n",
    "df = pd.DataFrame({'price': np.random.uniform(10, 100, 1000000)})\n",
    "\n",
    "# 2. Using Native Python Loop\n",
    "def loop_test():\n",
    "    taxed_prices = []\n",
    "    for p in df['price']:\n",
    "        taxed_prices.append(p * 1.10)\n",
    "    df['total_loop'] = taxed_prices\n",
    "\n",
    "# 3. Using Pandas Vectorisation\n",
    "def vectorized_test():\n",
    "    df['total_vector'] = df['price'] * 1.10\n",
    "\n",
    "# 4. Use timeit to measure the performance\n",
    "loop_time = timeit.timeit(loop_test, number=1)\n",
    "vector_time = timeit.timeit(vectorized_test, number=1)\n",
    "\n",
    "print(f\"Loop Method: {loop_time:.4f} seconds\")\n",
    "print(f\"Vectorized Method: {vector_time:.4f} seconds\")\n",
    "print(f\"Speedup Factor: {loop_time / vector_time:.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
